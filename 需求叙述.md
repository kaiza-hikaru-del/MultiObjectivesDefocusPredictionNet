# PyTorch 工程代码需求
本次生成代码的需求在于数据集加载代码的生成，以下是需求的详细说明

数据集的根目录应当是一个可以被传入的参数，使用 pathlib 库进行管理，类型应当是 pathlib 中提供的 Path
数据集根目录下面一定存在的三个目录 `.train` `.val` `.test` 分别对应着训练集验证集和测试集，应当提供一个字符串参数决定构造哪个数据集
同时构造数据集时应当可以传入一个 glob 字符串，默认为 `*`，也可以传入其他字符串进行筛选，例如 `10x_0.3*`
数据集中 `.xxx` 目录下为一系列 `csv` 文件，每个文件中都有这样几列，列名和对应的语义如下
`image_path,sobel_sharpness,defocus_label,magnification,NA,defocus_dof_label`
图像目录、sobel 清晰度、离焦距离标签、放大倍率、数值孔径、离焦分数标签
其中图像目录为相对路径，需要拼接上根目录转换为绝对路径进行图像读取
对于网络，其输入除了图像外，magnification 和 NA 也是输入参数，输出为 defocus_dof_label，除图像外别的参数都是浮点数

简而言之，构造数据集对象时应当传入数据集根目录、筛选字符串和数据集选择字符串
使用数据集时应当返回图像、额外的二维输入参数和一维网络输出

# 第二次对话
上面的叙述存在一些二义性，我将补充一些需求来请你帮我生成更符合需求的代码

首先构造数据集的类名使用 MOAFDataset 更为合适

构造方法中 glob_pattern 的默认参数使用 `*.csv` 更加合适，避免其他文件的干扰提升容错性

glob_pattern 在后续使用中也将严格传入含有 `.csv` 的子串提升容错

构造时再增加一个参数为 transform 方便在构造时适合不同需求

同时需要说明的是，csv 文件中的相对路径是相对于传入数据集根目录的，而非相对于 csv 所在路径的，因此直接拼接根路径和 csv 对应列中的相对路径即可

# 第四次对话
请类比 MOAFDataset 生成另一个数据集类，名为 SOAFDataset

与 MOAFDataset 的构造传入参数一致，但将 glob_pattern 的默认参数改为 `10x_0.3*.csv`

但 SOAFDataset 数据集与普通的图像分类/回归数据集类似，网络输入为图像，输出为一个数值

输入图像路径仍然为相对路径，需要拼接根路径，输出数值改变为这一列 `defocus_label`

# 模型需求
请根据以下具体需求帮助我生成一段 PyTorch 模型代码，除了使用到 PyTorch 相关库外，还需要使用到 timm 库
该模型输入为 224x224x3 的 RGB 彩色图像，输出为一个数值，与 SOAFDataset 数据集结构呼应
模型使用 timm 库内置的 create_model 方法，通过 feature_only 或类似的参数指定仅使用特征提取器部分
然后构建一个全连接网络，将特征提取器的输出最终映射到一维向量输出，该全连接网络含有两个中间层
将特征提取器输出的向量依次降维到 256、128 直到 1 维，全连接中每一层都增加激活函数 ReLU

在 main 测试中，除了加载模型并测试输入输出外，再增加一个功能输出为 onnx 模型，方便后续查看模型的计算图

# 模型修改需求
请根据我对代码中的 TODO 叙述进行修改
```py
import torch
import timm
from torch import nn
from torchinfo import summary

class SOAFModel(nn.Module):
    def __init__(self, 
                 model_name: str = "mobilenetv4_conv_small", 
                 pretrained: bool = True):
        super().__init__()
        
        # 创建特征提取器
        self.feature_extractor = timm.create_model(
            model_name,
            pretrained=pretrained,
            features_only=True,  # 仅获取特征图
            out_indices=(4,),    # 选择最后一个特征层 TODO 使用 -1 保证使用了全部的特征提取层
        )

        # 全局平均池化
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # 获取特征维度 TODO 应当首先经过全局池化再展平为特征向量
        dummy_input = torch.randn(1, 3, 224, 224)
        with torch.no_grad():
            features = self.global_pool(self.feature_extractor(dummy_input)[0])
        feature_dim = features.view(features.size(0), -1).shape[-1]

        # 构建全连接网络
        self.fc = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        # 提取特征
        features = self.feature_extractor(x)[0]  # 获取最后一个特征层
        
        # 池化 + 展平
        pooled = self.global_pool(features)
        flattened = torch.flatten(pooled, 1)
        
        # 全连接回归
        return self.fc(flattened)


def export_onnx(model, device, save_path="soaf_model.onnx"):
    dummy_input = torch.randn(1, 3, 224, 224).to(device)
    torch.onnx.export(
        model,
        dummy_input,
        save_path,
        input_names=["input"],
        output_names=["output"],
        dynamic_axes={
            "input": {0: "batch_size"},
            "output": {0: "batch_size"}
        }
    )
    print(f"ONNX模型已导出至: {save_path}")


if __name__ == "__main__":
    # 初始化模型
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = SOAFModel().to(device)
    
    # 打印模型结构
    model.eval()
    summary(model, input_size=(1, 3, 224, 224))
    
    # 测试推理
    test_input = torch.randn(1, 3, 224, 224).to(device)
    output = model(test_input)
    print(f"\n测试输出形状: {output.shape}\n")  # 预期输出: torch.Size([1, 1])
    
    # 导出ONNX
    export_onnx(model, device)
```

# 模型训练需求
以下两部分分别是数据集构建代码以及模型构架代码，请根据这两段代码生成训练代码和测试代码，具体要求如下
训练代码形成文件为 `myTrain.py`，包含数据集加载、模型训练与验证、检查点保存与读取等功能
主要涉及到的超参数有 epochs、lr、batch_size、num_works 等，同时需要有特征提取器字符串作为超参数
初始值 epochs=800, lr=1e-5, batch_size=32, num_works=8, fe_str="mobilenetv4_conv_small"

训练代码中，希望将训练一轮和验证一轮抽象出一个函数，分别为 `train_epoch(...)` 和 `validation_epoch(...)`
两个函数分别返回一个 Loss 值，用于中间结果的输出

损失函数使用 L1 损失，其具有对应的物理含义，优化器使用 Adam 优化器

检查点保存功能不仅需要保存当下模型权重，还需要保存当前轮数，优化器状态等必要的信息
检查点保存在 .ckpts/ 文件夹中，检查点模型命名大致应当是 `ckpt_<epoch>.pt`，并根据验证损失保存 `ckpt_best_<epoch>.pt`
检查点保存也意味着训练主代码应当有检查点恢复的功能，通过 `ckpt_best_<epoch>.pt` 进行恢复，如果不存在则从头训练
best 检查点每轮训练都需要进行比较是否保存，一般检查点的保存无需每轮都保存，而是根据下面的规律进行保存
`epoch < 200 and epoch % 10 == 0` 或 `epoch < 400 and epoch % 5 == 0` 或 `epoch < 600 and epoch % 3 == 0` 或 `epoch < 800`
也即当开始 200 轮时隔 10 个保存一次，200~400 轮时间隔 5 个保存一次，400~600 轮时间隔 3 个保存一次，600+ 轮时每次都保存

同样，请使用 tensorboard 可视化训练损失、验证损失和学习率变化，使用 with 进行对 writer 的上下文管理，不要使用 try-catch 语句
这样可以保证随时使用 Ctrl-C 停止训练但正确结束 writer
检查点的加载也可以保证每次接续训练时 tensorboard 可视化曲线不会从头开始

以下是数据集代码和模型代码
```py
# myDataset.py
# 单物镜数据集
class SOAFDataset(Dataset):
    def __init__(
        self,
        root_dir: Path,
        dataset_type: str,
        transform = None,
        glob_pattern: str = "10x_0.3*.csv"
    ):
        super().__init__()
        
        # 参数验证
        if dataset_type not in {'train', 'val', 'test'}:
            raise ValueError("dataset_type 必须是 'train', 'val' 或 'test'")
        if not isinstance(root_dir, Path):
            raise TypeError("root_dir 必须是 pathlib.Path 对象")
        if '.csv' not in glob_pattern:
            raise ValueError("glob_pattern 必须包含 '.csv' 扩展名")

        # 构建数据集路径
        self.root_dir = root_dir
        self.dataset_dir = root_dir / f".{dataset_type}"
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"数据集目录 {self.dataset_dir} 不存在")

        # 加载并合并CSV文件
        csv_files = list(self.dataset_dir.glob(glob_pattern))
        if not csv_files:
            raise FileNotFoundError(f"未找到匹配 {glob_pattern} 的CSV文件")

        # 批量合并DataFrame
        dfs = [pd.read_csv(f) for f in csv_files]
        combined_df = pd.concat(dfs, ignore_index=True)

        # 列名验证
        required_cols = {'image_path', 'defocus_label'}
        missing_cols = required_cols - set(combined_df.columns)
        if missing_cols:
            raise ValueError(f"CSV文件缺少必要列: {missing_cols}")

        # 路径处理
        combined_df['abs_image_path'] = self.root_dir / combined_df['image_path']
        
        # 转换为高效数据结构
        self.image_paths = combined_df['abs_image_path'].tolist()
        self.labels = torch.tensor(
            combined_df['defocus_label'].values.astype(float),
            dtype=torch.float32
        )

        # 图像预处理
        self.transform = transform or transforms.ToTensor()

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # 加载图像
        img = Image.open(self.image_paths[idx]).convert('RGB')
        if self.transform:
            img = self.transform(img)
        
        return img, self.labels[idx]

# myModel.py
class SOAFModel(nn.Module):
    def __init__(self, 
                 model_name: str = "mobilenetv4_conv_small", 
                 pretrained: bool = True):
        super().__init__()
        
        # 创建特征提取器（使用-1获取最后一个特征层）
        self.feature_extractor = timm.create_model(
            model_name,
            pretrained=pretrained,
            features_only=True,
            out_indices=(-1,),  # 修改点1：使用-1获取最后一个特征层
        )

        # 全局平均池化
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # 获取特征维度（先池化再展平）
        dummy_input = torch.randn(1, 3, 224, 224)
        with torch.no_grad():
            # 修改点2：先池化再展平计算特征维度
            features = self.feature_extractor(dummy_input)[0]
            pooled_features = self.global_pool(features)
        feature_dim = pooled_features.view(pooled_features.size(0), -1).shape[-1]

        # 构建全连接网络
        self.fc = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        # 提取特征
        features = self.feature_extractor(x)[0]
        
        # 池化 + 展平
        pooled = self.global_pool(features)
        flattened = torch.flatten(pooled, 1)
        
        return self.fc(flattened)
```


# 训练代码修改需求
以下是上次生成的模型训练代码，请根据我的 TODO 要求修改相应的代码
```py
import argparse
import time
from pathlib import Path
import torch
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from myDataset import SOAFDataset
from myModel import SOAFModel
from torchvision import transforms


# 训练参数配置
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--root_dir', type=str, required=True, help='数据集根目录')
    parser.add_argument('--epochs', type=int, default=800)
    parser.add_argument('--lr', type=float, default=1e-5)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--num_workers', type=int, default=8)
    parser.add_argument('--fe_str', type=str, default='mobilenetv4_conv_small')
    parser.add_argument('--resume', action='store_true', help='从最佳检查点恢复训练')
    return parser.parse_args()


# 训练流程封装
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    total_loss = 0.0
    for images, labels in loader:
        images = images.to(device)
        labels = labels.unsqueeze(1).to(device)  # 保持维度一致
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item() * images.size(0)
    return total_loss / len(loader.dataset)


# 验证流程封装
def validation_epoch(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            labels = labels.unsqueeze(1).to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item() * images.size(0)
    return total_loss / len(loader.dataset)


# TODO 这里就不要使用单独的函数进行检查点保存了，直接在 main 逻辑中进行
# 检查点保存逻辑 只保存最好或需要的点
def save_checkpoint(state, is_best, filename, best_filename):
    if is_best:
        torch.save(state, best_filename)
    else:
        torch.save(state, filename)


# 主训练函数
def main():
    args = parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # 数据预处理
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor()
    ])
    val_transform = transforms.ToTensor()
    
    # 数据集加载
    train_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='train',
        transform=train_transform,
        glob_pattern="20x_0.7*.csv"
    )
    val_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='val',
        transform=val_transform,
        glob_pattern="20x_0.7*.csv"
    )
    
    train_loader = DataLoader(
        train_set,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    val_loader = DataLoader(
        val_set,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    print("Data loaded")
    
    # 模型初始化
    model = SOAFModel(model_name=args.fe_str).to(device)
    criterion = torch.nn.L1Loss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    
    # 检查点设置
    ckpt_dir = Path('.ckpts')
    ckpt_dir.mkdir(exist_ok=True)
    best_ckpt = ckpt_dir / 'ckpt_best.pt'
    
    start_epoch = 0
    best_loss = float('inf')
    print("Model created")
    
    # 恢复训练
    if args.resume and best_ckpt.exists():
        checkpoint = torch.load(best_ckpt)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch'] + 1
        best_loss = checkpoint['best_loss']
        print(f'从检查点恢复训练，当前轮数：{start_epoch}，最佳损失：{best_loss:.4f}')
    
    # TensorBoard配置
    with SummaryWriter('runs/experiment') as writer:
        for epoch in range(start_epoch, args.epochs):
            start_time = time.time()
            
            # 训练与验证
            train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
            val_loss = validation_epoch(model, val_loader, criterion, device)
            
            # 学习率记录
            current_lr = optimizer.param_groups[0]['lr']
            
            # TensorBoard记录
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('Loss/val', val_loss, epoch)
            writer.add_scalar('Learning Rate', current_lr, epoch)
            
            # TODO 检查点保存逻辑两个是独立的
            # TODO save_regular 条件下按照 epoch 命名检查点并保存
            # TODO 每一轮都检查是否变得更好，保存为 ckpt_best
            # 检查点保存逻辑
            is_best = val_loss < best_loss
            best_loss = min(val_loss, best_loss)
            
            # 生成检查点文件名
            ckpt_path = ckpt_dir / f'ckpt_{epoch:04d}.pt'
            
            # 按条件保存常规检查点
            save_regular = False
            if epoch < 200 and epoch % 10 == 0:
                save_regular = True
            elif epoch < 400 and epoch % 5 == 0:
                save_regular = True
            elif epoch < 600 and epoch % 3 == 0:
                save_regular = True
            elif epoch >= 600:
                save_regular = True
                
            if save_regular or is_best:
                save_checkpoint(
                    {
                        'epoch': epoch,
                        'model': model.state_dict(),
                        'optimizer': optimizer.state_dict(),
                        'best_loss': best_loss,
                        'args': vars(args)
                    },
                    is_best=is_best,
                    filename=ckpt_path,
                    best_filename=best_ckpt
                )
            
            # 训练信息输出
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch+1}/{args.epochs} | '
                  f'Train Loss: {train_loss:.4f} | '
                  f'Val Loss: {val_loss:.4f} | '
                  f'Time: {epoch_time:.2f}s')


if __name__ == '__main__':
    main()
```

# 测试代码需求
请根据之前的信息，生成一段用于模型测试的代码，具体要求如下
测试代码同样导入 SOAFDataset 和 SOAFModel，使用 'test' 集并加载 'best_ckpt.pt'
并且使用一个函数将 pt 模型转换为 onnx 模型，所有 onnx 模型保存在 `.onnx` 目录下
同时测试 pt 模型的性能和 onnx 模型的性能
对于所有测试集中的数据应当形成一个测试表格 csv 文件，保存在 `.result` 目录下
这个 csv 文件应当至少有以下几列，列名与对应的语义如下
['image_path', 'label', 'pt_pred', 'onnx_pred', 'onnx_time_cost']
分别指图像路径、标签、pt 模型预测结果、onnx 模型预测结果、onnx 模型耗时
其中 pt 模型测试时可以使用类似训练时的 batch_size 参数快速测试
而 onnx 模型测试时只能固定 batch_size=1 进行测试以保证推理时间测试的准确性
测试代码 `myTest.py` 可传入参数与 `myTrain.py` 类似，但不再有 epochs, lr, resume 这三个参数



