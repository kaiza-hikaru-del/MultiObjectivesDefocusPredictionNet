# PyTorch 工程代码需求
本次生成代码的需求在于数据集加载代码的生成，以下是需求的详细说明

数据集的根目录应当是一个可以被传入的参数，使用 pathlib 库进行管理，类型应当是 pathlib 中提供的 Path
数据集根目录下面一定存在的三个目录 `.train` `.val` `.test` 分别对应着训练集验证集和测试集，应当提供一个字符串参数决定构造哪个数据集
同时构造数据集时应当可以传入一个 glob 字符串，默认为 `*`，也可以传入其他字符串进行筛选，例如 `10x_0.3*`
数据集中 `.xxx` 目录下为一系列 `csv` 文件，每个文件中都有这样几列，列名和对应的语义如下
`image_path,sobel_sharpness,defocus_label,magnification,NA,defocus_dof_label`
图像目录、sobel 清晰度、离焦距离标签、放大倍率、数值孔径、离焦分数标签
其中图像目录为相对路径，需要拼接上根目录转换为绝对路径进行图像读取
对于网络，其输入除了图像外，magnification 和 NA 也是输入参数，输出为 defocus_dof_label，除图像外别的参数都是浮点数

简而言之，构造数据集对象时应当传入数据集根目录、筛选字符串和数据集选择字符串
使用数据集时应当返回图像、额外的二维输入参数和一维网络输出

# 第二次对话
上面的叙述存在一些二义性，我将补充一些需求来请你帮我生成更符合需求的代码

首先构造数据集的类名使用 MOAFDataset 更为合适

构造方法中 glob_pattern 的默认参数使用 `*.csv` 更加合适，避免其他文件的干扰提升容错性

glob_pattern 在后续使用中也将严格传入含有 `.csv` 的子串提升容错

构造时再增加一个参数为 transform 方便在构造时适合不同需求

同时需要说明的是，csv 文件中的相对路径是相对于传入数据集根目录的，而非相对于 csv 所在路径的，因此直接拼接根路径和 csv 对应列中的相对路径即可

# 第四次对话
请类比 MOAFDataset 生成另一个数据集类，名为 SOAFDataset

与 MOAFDataset 的构造传入参数一致，但将 glob_pattern 的默认参数改为 `10x_0.3*.csv`

但 SOAFDataset 数据集与普通的图像分类/回归数据集类似，网络输入为图像，输出为一个数值

输入图像路径仍然为相对路径，需要拼接根路径，输出数值改变为这一列 `defocus_label`

# 模型需求
请根据以下具体需求帮助我生成一段 PyTorch 模型代码，除了使用到 PyTorch 相关库外，还需要使用到 timm 库
该模型输入为 224x224x3 的 RGB 彩色图像，输出为一个数值，与 SOAFDataset 数据集结构呼应
模型使用 timm 库内置的 create_model 方法，通过 feature_only 或类似的参数指定仅使用特征提取器部分
然后构建一个全连接网络，将特征提取器的输出最终映射到一维向量输出，该全连接网络含有两个中间层
将特征提取器输出的向量依次降维到 256、128 直到 1 维，全连接中每一层都增加激活函数 ReLU

在 main 测试中，除了加载模型并测试输入输出外，再增加一个功能输出为 onnx 模型，方便后续查看模型的计算图

# 模型修改需求
请根据我对代码中的 TODO 叙述进行修改
```py
import torch
import timm
from torch import nn
from torchinfo import summary

class SOAFModel(nn.Module):
    def __init__(self, 
                 model_name: str = "mobilenetv4_conv_small", 
                 pretrained: bool = True):
        super().__init__()
        
        # 创建特征提取器
        self.feature_extractor = timm.create_model(
            model_name,
            pretrained=pretrained,
            features_only=True,  # 仅获取特征图
            out_indices=(4,),    # 选择最后一个特征层 TODO 使用 -1 保证使用了全部的特征提取层
        )

        # 全局平均池化
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # 获取特征维度 TODO 应当首先经过全局池化再展平为特征向量
        dummy_input = torch.randn(1, 3, 224, 224)
        with torch.no_grad():
            features = self.global_pool(self.feature_extractor(dummy_input)[0])
        feature_dim = features.view(features.size(0), -1).shape[-1]

        # 构建全连接网络
        self.fc = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        # 提取特征
        features = self.feature_extractor(x)[0]  # 获取最后一个特征层
        
        # 池化 + 展平
        pooled = self.global_pool(features)
        flattened = torch.flatten(pooled, 1)
        
        # 全连接回归
        return self.fc(flattened)


def export_onnx(model, device, save_path="soaf_model.onnx"):
    dummy_input = torch.randn(1, 3, 224, 224).to(device)
    torch.onnx.export(
        model,
        dummy_input,
        save_path,
        input_names=["input"],
        output_names=["output"],
        dynamic_axes={
            "input": {0: "batch_size"},
            "output": {0: "batch_size"}
        }
    )
    print(f"ONNX模型已导出至: {save_path}")


if __name__ == "__main__":
    # 初始化模型
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = SOAFModel().to(device)
    
    # 打印模型结构
    model.eval()
    summary(model, input_size=(1, 3, 224, 224))
    
    # 测试推理
    test_input = torch.randn(1, 3, 224, 224).to(device)
    output = model(test_input)
    print(f"\n测试输出形状: {output.shape}\n")  # 预期输出: torch.Size([1, 1])
    
    # 导出ONNX
    export_onnx(model, device)
```

# 模型训练需求
以下两部分分别是数据集构建代码以及模型构架代码，请根据这两段代码生成训练代码和测试代码，具体要求如下
训练代码形成文件为 `myTrain.py`，包含数据集加载、模型训练与验证、检查点保存与读取等功能
主要涉及到的超参数有 epochs、lr、batch_size、num_works 等，同时需要有特征提取器字符串作为超参数
初始值 epochs=800, lr=1e-5, batch_size=32, num_works=8, fe_str="mobilenetv4_conv_small"

训练代码中，希望将训练一轮和验证一轮抽象出一个函数，分别为 `train_epoch(...)` 和 `validation_epoch(...)`
两个函数分别返回一个 Loss 值，用于中间结果的输出

损失函数使用 L1 损失，其具有对应的物理含义，优化器使用 Adam 优化器

检查点保存功能不仅需要保存当下模型权重，还需要保存当前轮数，优化器状态等必要的信息
检查点保存在 .ckpts/ 文件夹中，检查点模型命名大致应当是 `ckpt_<epoch>.pt`，并根据验证损失保存 `ckpt_best_<epoch>.pt`
检查点保存也意味着训练主代码应当有检查点恢复的功能，通过 `ckpt_best_<epoch>.pt` 进行恢复，如果不存在则从头训练
best 检查点每轮训练都需要进行比较是否保存，一般检查点的保存无需每轮都保存，而是根据下面的规律进行保存
`epoch < 200 and epoch % 10 == 0` 或 `epoch < 400 and epoch % 5 == 0` 或 `epoch < 600 and epoch % 3 == 0` 或 `epoch < 800`
也即当开始 200 轮时隔 10 个保存一次，200~400 轮时间隔 5 个保存一次，400~600 轮时间隔 3 个保存一次，600+ 轮时每次都保存

同样，请使用 tensorboard 可视化训练损失、验证损失和学习率变化，使用 with 进行对 writer 的上下文管理，不要使用 try-catch 语句
这样可以保证随时使用 Ctrl-C 停止训练但正确结束 writer
检查点的加载也可以保证每次接续训练时 tensorboard 可视化曲线不会从头开始

以下是数据集代码和模型代码
```py
# myDataset.py
# 单物镜数据集
class SOAFDataset(Dataset):
    def __init__(
        self,
        root_dir: Path,
        dataset_type: str,
        transform = None,
        glob_pattern: str = "10x_0.3*.csv"
    ):
        super().__init__()
        
        # 参数验证
        if dataset_type not in {'train', 'val', 'test'}:
            raise ValueError("dataset_type 必须是 'train', 'val' 或 'test'")
        if not isinstance(root_dir, Path):
            raise TypeError("root_dir 必须是 pathlib.Path 对象")
        if '.csv' not in glob_pattern:
            raise ValueError("glob_pattern 必须包含 '.csv' 扩展名")

        # 构建数据集路径
        self.root_dir = root_dir
        self.dataset_dir = root_dir / f".{dataset_type}"
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"数据集目录 {self.dataset_dir} 不存在")

        # 加载并合并CSV文件
        csv_files = list(self.dataset_dir.glob(glob_pattern))
        if not csv_files:
            raise FileNotFoundError(f"未找到匹配 {glob_pattern} 的CSV文件")

        # 批量合并DataFrame
        dfs = [pd.read_csv(f) for f in csv_files]
        combined_df = pd.concat(dfs, ignore_index=True)

        # 列名验证
        required_cols = {'image_path', 'defocus_label'}
        missing_cols = required_cols - set(combined_df.columns)
        if missing_cols:
            raise ValueError(f"CSV文件缺少必要列: {missing_cols}")

        # 路径处理
        combined_df['abs_image_path'] = self.root_dir / combined_df['image_path']
        
        # 转换为高效数据结构
        self.image_paths = combined_df['abs_image_path'].tolist()
        self.labels = torch.tensor(
            combined_df['defocus_label'].values.astype(float),
            dtype=torch.float32
        )

        # 图像预处理
        self.transform = transform or transforms.ToTensor()

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # 加载图像
        img = Image.open(self.image_paths[idx]).convert('RGB')
        if self.transform:
            img = self.transform(img)
        
        return img, self.labels[idx]

# myModel.py
class SOAFModel(nn.Module):
    def __init__(self, 
                 model_name: str = "mobilenetv4_conv_small", 
                 pretrained: bool = True):
        super().__init__()
        
        # 创建特征提取器（使用-1获取最后一个特征层）
        self.feature_extractor = timm.create_model(
            model_name,
            pretrained=pretrained,
            features_only=True,
            out_indices=(-1,),  # 修改点1：使用-1获取最后一个特征层
        )

        # 全局平均池化
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # 获取特征维度（先池化再展平）
        dummy_input = torch.randn(1, 3, 224, 224)
        with torch.no_grad():
            # 修改点2：先池化再展平计算特征维度
            features = self.feature_extractor(dummy_input)[0]
            pooled_features = self.global_pool(features)
        feature_dim = pooled_features.view(pooled_features.size(0), -1).shape[-1]

        # 构建全连接网络
        self.fc = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        # 提取特征
        features = self.feature_extractor(x)[0]
        
        # 池化 + 展平
        pooled = self.global_pool(features)
        flattened = torch.flatten(pooled, 1)
        
        return self.fc(flattened)
```


# 训练代码修改需求
以下是上次生成的模型训练代码，请根据我的 TODO 要求修改相应的代码
```py
import argparse
import time
from pathlib import Path
import torch
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from myDataset import SOAFDataset
from myModel import SOAFModel
from torchvision import transforms


# 训练参数配置
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--root_dir', type=str, required=True, help='数据集根目录')
    parser.add_argument('--epochs', type=int, default=800)
    parser.add_argument('--lr', type=float, default=1e-5)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--num_workers', type=int, default=8)
    parser.add_argument('--fe_str', type=str, default='mobilenetv4_conv_small')
    parser.add_argument('--resume', action='store_true', help='从最佳检查点恢复训练')
    return parser.parse_args()


# 训练流程封装
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    total_loss = 0.0
    for images, labels in loader:
        images = images.to(device)
        labels = labels.unsqueeze(1).to(device)  # 保持维度一致
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item() * images.size(0)
    return total_loss / len(loader.dataset)


# 验证流程封装
def validation_epoch(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            labels = labels.unsqueeze(1).to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item() * images.size(0)
    return total_loss / len(loader.dataset)


# TODO 这里就不要使用单独的函数进行检查点保存了，直接在 main 逻辑中进行
# 检查点保存逻辑 只保存最好或需要的点
def save_checkpoint(state, is_best, filename, best_filename):
    if is_best:
        torch.save(state, best_filename)
    else:
        torch.save(state, filename)


# 主训练函数
def main():
    args = parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # 数据预处理
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor()
    ])
    val_transform = transforms.ToTensor()
    
    # 数据集加载
    train_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='train',
        transform=train_transform,
        glob_pattern="20x_0.7*.csv"
    )
    val_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='val',
        transform=val_transform,
        glob_pattern="20x_0.7*.csv"
    )
    
    train_loader = DataLoader(
        train_set,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    val_loader = DataLoader(
        val_set,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    print("Data loaded")
    
    # 模型初始化
    model = SOAFModel(model_name=args.fe_str).to(device)
    criterion = torch.nn.L1Loss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    
    # 检查点设置
    ckpt_dir = Path('.ckpts')
    ckpt_dir.mkdir(exist_ok=True)
    best_ckpt = ckpt_dir / 'ckpt_best.pt'
    
    start_epoch = 0
    best_loss = float('inf')
    print("Model created")
    
    # 恢复训练
    if args.resume and best_ckpt.exists():
        checkpoint = torch.load(best_ckpt)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch'] + 1
        best_loss = checkpoint['best_loss']
        print(f'从检查点恢复训练，当前轮数：{start_epoch}，最佳损失：{best_loss:.4f}')
    
    # TensorBoard配置
    with SummaryWriter('runs/experiment') as writer:
        for epoch in range(start_epoch, args.epochs):
            start_time = time.time()
            
            # 训练与验证
            train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
            val_loss = validation_epoch(model, val_loader, criterion, device)
            
            # 学习率记录
            current_lr = optimizer.param_groups[0]['lr']
            
            # TensorBoard记录
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('Loss/val', val_loss, epoch)
            writer.add_scalar('Learning Rate', current_lr, epoch)
            
            # TODO 检查点保存逻辑两个是独立的
            # TODO save_regular 条件下按照 epoch 命名检查点并保存
            # TODO 每一轮都检查是否变得更好，保存为 ckpt_best
            # 检查点保存逻辑
            is_best = val_loss < best_loss
            best_loss = min(val_loss, best_loss)
            
            # 生成检查点文件名
            ckpt_path = ckpt_dir / f'ckpt_{epoch:04d}.pt'
            
            # 按条件保存常规检查点
            save_regular = False
            if epoch < 200 and epoch % 10 == 0:
                save_regular = True
            elif epoch < 400 and epoch % 5 == 0:
                save_regular = True
            elif epoch < 600 and epoch % 3 == 0:
                save_regular = True
            elif epoch >= 600:
                save_regular = True
                
            if save_regular or is_best:
                save_checkpoint(
                    {
                        'epoch': epoch,
                        'model': model.state_dict(),
                        'optimizer': optimizer.state_dict(),
                        'best_loss': best_loss,
                        'args': vars(args)
                    },
                    is_best=is_best,
                    filename=ckpt_path,
                    best_filename=best_ckpt
                )
            
            # 训练信息输出
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch+1}/{args.epochs} | '
                  f'Train Loss: {train_loss:.4f} | '
                  f'Val Loss: {val_loss:.4f} | '
                  f'Time: {epoch_time:.2f}s')


if __name__ == '__main__':
    main()
```

# 测试代码需求
请根据之前的信息，生成一段用于模型测试的代码，具体要求如下
测试代码同样导入 SOAFDataset 和 SOAFModel，使用 'test' 集并加载 'best_ckpt.pt'
并且使用一个函数将 pt 模型转换为 onnx 模型，所有 onnx 模型保存在 `.onnx` 目录下
同时测试 pt 模型的性能和 onnx 模型的性能
对于所有测试集中的数据应当形成一个测试表格 csv 文件，保存在 `.result` 目录下
这个 csv 文件应当至少有以下几列，列名与对应的语义如下
['image_path', 'label', 'pt_pred', 'onnx_pred', 'onnx_time_cost']
分别指图像路径、标签、pt 模型预测结果、onnx 模型预测结果、onnx 模型耗时
其中 pt 模型测试时可以使用类似训练时的 batch_size 参数快速测试
而 onnx 模型测试时只能固定 batch_size=1 进行测试以保证推理时间测试的准确性
测试代码 `myTest.py` 可传入参数与 `myTrain.py` 类似，但不再有 epochs, lr, resume 这三个参数

# 多参数物镜模型需求
以下我将给出单物镜下离焦预测数据集与模型的相关代码，包括数据集构建、模型构建、训练与测试代码，请仿照单物镜代码写出多参数物镜离焦预测代码
接下来是详细需求叙述，在整体结构上与单物镜类似，多物镜数据集加载代码已经写出，在 `myDataset.py` 中以 `class MOAFDataset` 呈现
这个数据集使用时返回一张图像，一个二维辅助输入向量（物理含义为数值孔径和放大倍率），一个一维向量输出（物理含义为离焦程度）

多物镜模型类名为 `MOAFModel`，与 SOAFModel 类似，使用 timm 库的 create_model 并配合别的参数加载一个现有的特征提取器
然后进行 GlobalAvgPool 变换为特征向量，并首先通过全连接网络依次降维到 256 和 64，成为降维后的特征向量
再然后，用到 FiLM 的思想，将二维辅助输入向量首先依次升维到 64 和 128，再将升维后的结果分成 2 个 64 维向量，使用 FiLM 方法与降维后特征向量融合
融合后仍然为 64 维向量，然后依次降维到 32 和 1 维得到最终输出

新模型直接实现在 `myModel.py` 中，其 main 逻辑中，添加将该模型转换为 onnx 测试以及用 torchinfo 输出统计信息的功能

至于对 MOAFModel 训练和测试的代码将在之后进行编写，目前请帮助我将这个模型进行构造，以下是目前工程中相关代码
```py
# myDataset.py
import torch
from torch.utils.data import Dataset
from pathlib import Path
import pandas as pd
from PIL import Image
from torchvision import transforms

import time


# 多物镜数据集
class MOAFDataset(Dataset):
    def __init__(
        self,
        root_dir: Path,
        dataset_type: str,
        transform = None,
        glob_pattern: str = "*.csv"
    ):
        super().__init__()
        
        # 参数验证
        if dataset_type not in {'train', 'val', 'test'}:
            raise ValueError("dataset_type 必须是 'train', 'val' 或 'test'")
        if not isinstance(root_dir, Path):
            raise TypeError("root_dir 必须是 pathlib.Path 对象")
        if '.csv' not in glob_pattern:
            raise ValueError("glob_pattern 必须包含 '.csv' 扩展名")

        # 构建数据集路径
        self.root_dir = root_dir
        self.dataset_dir = root_dir / f".{dataset_type}"
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"数据集目录 {self.dataset_dir} 不存在")

        # 并行加载所有CSV文件
        csv_files = list(self.dataset_dir.glob(glob_pattern))
        if not csv_files:
            raise FileNotFoundError(f"未找到匹配 {glob_pattern} 的CSV文件")

        # 使用pd.concat一次性合并所有DataFrame
        dfs = [pd.read_csv(f) for f in csv_files]
        combined_df = pd.concat(dfs, ignore_index=True)

        # 列名验证（合并后只需验证一次）
        required_cols = {'image_path', 'magnification', 'NA', 'defocus_dof_label'}
        missing_cols = required_cols - set(combined_df.columns)
        if missing_cols:
            raise ValueError(f"CSV文件缺少必要列: {missing_cols}")

        # 向量化处理路径
        combined_df['abs_image_path'] = root_dir / combined_df['image_path']
        
        # 转换为绝对路径列表（替代字典存储）
        self.image_paths = combined_df['abs_image_path'].tolist()
        
        # 预处理数值特征（提前转换为张量）
        self.features = torch.tensor(
            combined_df[['magnification', 'NA']].values.astype(float),
            dtype=torch.float32
        )
        
        # 预处理标签
        self.labels = torch.tensor(
            combined_df['defocus_dof_label'].values.astype(float),
            dtype=torch.float32
        )

        # 图像预处理管道
        self.transform = transform or transforms.ToTensor()

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # 读取图像
        img = Image.open(self.image_paths[idx]).convert('RGB')
        if self.transform:
            img = self.transform(img)
        
        # 直接返回预处理的张量
        return img, self.features[idx], self.labels[idx]


# 单物镜数据集
class SOAFDataset(Dataset):
    def __init__(
        self,
        root_dir: Path,
        dataset_type: str,
        transform = None,
        glob_pattern: str = "10x_0.3*.csv"
    ):
        super().__init__()
        
        # 参数验证
        if dataset_type not in {'train', 'val', 'test'}:
            raise ValueError("dataset_type 必须是 'train', 'val' 或 'test'")
        if not isinstance(root_dir, Path):
            raise TypeError("root_dir 必须是 pathlib.Path 对象")
        if '.csv' not in glob_pattern:
            raise ValueError("glob_pattern 必须包含 '.csv' 扩展名")

        # 构建数据集路径
        self.root_dir = root_dir
        self.dataset_dir = root_dir / f".{dataset_type}"
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"数据集目录 {self.dataset_dir} 不存在")

        # 加载并合并CSV文件
        csv_files = list(self.dataset_dir.glob(glob_pattern))
        if not csv_files:
            raise FileNotFoundError(f"未找到匹配 {glob_pattern} 的CSV文件")

        # 批量合并DataFrame
        dfs = [pd.read_csv(f) for f in csv_files]
        combined_df = pd.concat(dfs, ignore_index=True)

        # 列名验证
        required_cols = {'image_path', 'defocus_label'}
        missing_cols = required_cols - set(combined_df.columns)
        if missing_cols:
            raise ValueError(f"CSV文件缺少必要列: {missing_cols}")

        # 路径处理
        combined_df['abs_image_path'] = self.root_dir / combined_df['image_path']
        
        # 转换为高效数据结构
        self.image_paths = combined_df['abs_image_path'].tolist()
        self.labels = torch.tensor(
            combined_df['defocus_label'].values.astype(float),
            dtype=torch.float32
        )

        # 图像预处理
        self.transform = transform or transforms.ToTensor()

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # 加载图像
        img = Image.open(self.image_paths[idx]).convert('RGB')
        if self.transform:
            img = self.transform(img)
        
        return img, self.labels[idx]

# myModel.py
import torch
import timm
from torch import nn
from torchinfo import summary

class SOAFModel(nn.Module):
    def __init__(self, 
                 model_name: str = "mobilenetv4_conv_small", 
                 pretrained: bool = True):
        super().__init__()
        
        # 创建特征提取器（使用-1获取最后一个特征层）
        self.feature_extractor = timm.create_model(
            model_name,
            pretrained=pretrained,
            features_only=True,
            out_indices=(-1,),  # 修改点1：使用-1获取最后一个特征层
        )

        # 全局平均池化
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # 获取特征维度（先池化再展平）
        dummy_input = torch.randn(1, 3, 224, 224)
        with torch.no_grad():
            # 修改点2：先池化再展平计算特征维度
            features = self.feature_extractor(dummy_input)[0]
            pooled_features = self.global_pool(features)
        feature_dim = pooled_features.view(pooled_features.size(0), -1).shape[-1]

        # 构建全连接网络
        self.fc = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        # 提取特征
        features = self.feature_extractor(x)[0]
        
        # 池化 + 展平
        pooled = self.global_pool(features)
        flattened = torch.flatten(pooled, 1)
        
        return self.fc(flattened)


if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = SOAFModel().to(device)

    # 验证修改后的特征维度计算
    test_input = torch.randn(2, 3, 224, 224).to(device)
    with torch.no_grad():
        features = model.feature_extractor(test_input)[0]
        pooled = model.global_pool(features)
        print(f"池化后特征形状: {pooled.shape}")  # 应显示如 torch.Size([2, 512, 1, 1])
        print(f"全连接输入维度: {model.fc[0].in_features}")  # 显示实际特征维度

    # 测试推理
    output = model(test_input)
    print(f"\n批量测试输出形状: {output.shape}")  # 应显示 torch.Size([2, 1])

    # 打印模型结构
    summary(model, input_size=(1, 3, 224, 224))

    # 导出ONNX
    model.eval()
    save_path = "test_soaf_model.onnx"
    dummy_input = torch.randn(1, 3, 224, 224).to(device)
    torch.onnx.export(
        model,
        dummy_input,
        save_path,
        input_names=["input"],
        output_names=["output"],
        dynamic_axes={
            "input": {0: "batch_size"},
            "output": {0: "batch_size"}
        },
        opset_version=13  # 添加明确的操作集版本
    )
    print(f"ONNX模型已导出至: {save_path}")

# TODO 添加 MOAFModel
```

# 训练与测试代码
请根据上述生成的 MOAFModel 模型代码，结合之前针对 SOAFModel 的训练与测试代码，编写对 MOAFModel 的训练与测试代码
以下为原先的 myTrainSO.py 和 myTestSO.py，请结合这两个文件生成对应的 myTrainMO.py 和 myTestMO.py
```py
# myTrainSO.py
import argparse
import time
from pathlib import Path
import torch
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from myDataset import SOAFDataset
from myModel import SOAFModel
from torchvision import transforms

from tqdm.rich import tqdm


# 训练参数配置
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--root_dir', type=str, required=True, help='数据集根目录')
    parser.add_argument('--epochs', type=int, default=800)
    parser.add_argument('--lr', type=float, default=1e-5)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--num_workers', type=int, default=8)
    parser.add_argument('--fe_str', type=str, default='mobilenetv4_conv_small')
    parser.add_argument('--resume', action='store_true', help='从最佳检查点恢复训练')
    return parser.parse_args()


# 训练流程封装
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    total_loss = 0.0
    for images, labels in tqdm(loader):
        images = images.to(device)
        labels = labels.unsqueeze(1).to(device)  # 保持维度一致
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item() * images.size(0)
    return total_loss / len(loader.dataset)


# 验证流程封装
def validation_epoch(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        for images, labels in tqdm(loader):
            images = images.to(device)
            labels = labels.unsqueeze(1).to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item() * images.size(0)
    return total_loss / len(loader.dataset)


# 主训练函数
def main():
    args = parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # 数据预处理
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor()
    ])
    val_transform = transforms.ToTensor()
    
    # 数据集加载
    train_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='train',
        transform=train_transform,
        glob_pattern="20x_0.7*.csv"
    )
    val_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='val',
        transform=val_transform,
        glob_pattern="20x_0.7*.csv"
    )
    
    train_loader = DataLoader(
        train_set,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    val_loader = DataLoader(
        val_set,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    print("Data loaded")
    
    # 模型初始化
    model = SOAFModel(model_name=args.fe_str).to(device)
    criterion = torch.nn.L1Loss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    
    # 检查点设置
    ckpt_dir = Path(f'.ckpts/SO_{args.fe_str}')
    ckpt_dir.mkdir(exist_ok=True, parents=True)
    best_ckpt = ckpt_dir / 'ckpt_best.pt'
    
    start_epoch = 0
    best_loss = float('inf')
    print("Model created")
    
    # 恢复训练
    if args.resume and best_ckpt.exists():
        checkpoint = torch.load(best_ckpt)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch'] + 1
        best_loss = checkpoint['best_loss']
        print(f'从检查点恢复训练，当前轮数：{start_epoch}，最佳损失：{best_loss:.4f}')
    
    # TensorBoard配置
    with SummaryWriter(f'.runs/SO_{args.fe_str}') as writer:
        for epoch in range(start_epoch, args.epochs):
            start_time = time.time()
            
            # 训练与验证
            train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
            val_loss = validation_epoch(model, val_loader, criterion, device)
            
            # 学习率记录
            current_lr = optimizer.param_groups[0]['lr']
            
            # TensorBoard记录
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('Loss/val', val_loss, epoch)
            writer.add_scalar('Learning Rate', current_lr, epoch)
            
            # 生成检查点文件名
            ckpt_path = ckpt_dir / f'ckpt_{epoch:04d}.pt'
            
            # 按条件保存常规检查点
            save_regular = False
            if epoch < 200 and epoch % 10 == 0:
                save_regular = True
            elif 200 <= epoch and epoch < 400 and epoch % 5 == 0:
                save_regular = True
            elif 400 <= epoch and epoch < 600 and epoch % 3 == 0:
                save_regular = True
            elif epoch >= 600:
                save_regular = True
                
            # 保存常规检查点（独立判断）
            if save_regular:
                torch.save({
                    'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': optimizer.state_dict(),
                    'best_loss': best_loss,
                    'args': vars(args)
                }, ckpt_path)
                print(f"保存常规检查点: {ckpt_path.name}")

            # 保存最佳检查点（独立判断）
            is_best = val_loss < best_loss
            if is_best:
                best_loss = val_loss
                torch.save({
                    'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': optimizer.state_dict(),
                    'best_loss': best_loss,
                    'args': vars(args)
                }, best_ckpt)
                print(f"保存最佳检查点: {best_ckpt.name} (loss={best_loss:.4f})")
            
            # 训练信息输出
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch+1}/{args.epochs} | '
                  f'Train Loss: {train_loss:.4f} | '
                  f'Val Loss: {val_loss:.4f} | '
                  f'Time: {epoch_time:.2f}s')


if __name__ == '__main__':
    main()

# myTestSO.py
import argparse
import time
import pandas as pd
from pathlib import Path
import numpy as np
import torch
import onnxruntime
from torch.utils.data import DataLoader
from myDataset import SOAFDataset
from myModel import SOAFModel
from torchvision import transforms

from tqdm.rich import tqdm


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--root_dir', type=str, required=True, help='数据集根目录')
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--num_workers', type=int, default=8)
    parser.add_argument('--fe_str', type=str, default='mobilenetv4_conv_small')
    return parser.parse_args()


def convert_to_onnx(pt_model, device, save_model):
    save_dir = Path(".onnx")
    save_dir.mkdir(exist_ok=True, parents=True)
    onnx_path = save_dir / f"SO_{save_model}_best.onnx"
    
    dummy_input = torch.randn(1, 3, 224, 224).to(device)
    
    torch.onnx.export(
        pt_model,
        dummy_input,
        onnx_path,
        input_names=["input"],
        output_names=["output"],
        dynamic_axes={
            "input": {0: "batch_size"},
            "output": {0: "batch_size"}
        },
        opset_version=13
    )
    return onnx_path


def test_pytorch_model(model, loader, device):
    model.eval()
    all_labels = []
    all_preds = []
    
    with torch.no_grad():
        for images, labels in tqdm(loader):
            images = images.to(device)
            outputs = model(images).cpu().numpy()
            
            all_labels.extend(labels.numpy())
            all_preds.extend(outputs.squeeze())
    
    return all_labels, all_preds


def test_onnx_model(onnx_path, dataset):
    session = onnxruntime.InferenceSession(onnx_path, providers=["CUDAExecutionProvider"])
    print(f"ONNX session providers: {session.get_providers()}")
    print(f"ONNX session provider options: {session.get_provider_options()}")
    all_preds = []
    time_costs = []
    
    for img, label in tqdm(dataset):
        img_tensor = img.unsqueeze(0).numpy()  # Add batch dimension
        
        start_time = time.perf_counter()
        pred = session.run(
            ["output"],
            {"input": img_tensor}
        )[0][0][0]
        time_cost = time.perf_counter() - start_time
        
        all_preds.append(pred)
        time_costs.append(time_cost)
    
    return all_preds, time_costs


def save_results(results, save_result):
    save_dir = Path(".results")
    save_dir.mkdir(exist_ok=True, parents=True)
    
    # 创建DataFrame并指定列名
    df = pd.DataFrame(results, columns=[
        'image_path', 
        'label', 
        'pt_pred', 
        'onnx_pred', 
        'onnx_time_cost'
    ])
    
    # 添加路径处理（可选）
    df['image_path'] = df['image_path'].astype(str)
    
    # 优化数据类型
    df = df.astype({
        'label': 'float32',
        'pt_pred': 'float32',
        'onnx_pred': 'float32',
        'onnx_time_cost': 'float64'
    })
    
    csv_path = save_dir / f"SO_{save_result}_results.csv"
    df.to_csv(csv_path, index=False)
    print(f"测试结果已保存至: {csv_path}")


def main():
    args = parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 加载测试集
    test_set = SOAFDataset(
        root_dir=Path(args.root_dir),
        dataset_type='test',
        transform=transforms.ToTensor(),
        glob_pattern="20x_0.7*.csv"
    )
    
    # 创建PyTorch数据加载器
    test_loader = DataLoader(
        test_set,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers
    )
    
    # 初始化模型并加载最佳检查点
    model = SOAFModel(model_name=args.fe_str).to(device)
    ckpt = torch.load(Path('.ckpts') / f"SO_{args.fe_str}" / 'ckpt_best.pt')
    model.load_state_dict(ckpt['model'])
    
    # 转换ONNX模型
    onnx_path = convert_to_onnx(model, device, args.fe_str)
    print(f"ONNX模型已保存至: {onnx_path}")
    
    # 测试PyTorch模型
    labels, pt_preds = test_pytorch_model(model, test_loader, device)
    print("PyTorch模型测试结束")
    
    # 测试ONNX模型
    onnx_preds, onnx_times = test_onnx_model(onnx_path, test_set)
    print("ONNX模型测试结束")
    
    # 收集结果
    results = []
    for i in range(len(test_set)):
        results.append((
            str(test_set.image_paths[i]),  # 原始路径已转换为绝对路径
            labels[i],
            pt_preds[i],
            onnx_preds[i],
            onnx_times[i]
        ))
    
    # 保存结果
    save_results(results, args.fe_str)

if __name__ == '__main__':
    main()
```

# 
